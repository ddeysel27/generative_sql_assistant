{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "875e0af7",
   "metadata": {},
   "source": [
    "## Import model from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4060c367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SentencePiece loaded, version: 0.2.1\n",
      "âœ… PyTorch loaded, version: 2.8.0+cpu\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "print(\"âœ… SentencePiece loaded, version:\", spm.__version__)\n",
    "\n",
    "import torch\n",
    "print(\"âœ… PyTorch loaded, version:\", torch.__version__) \n",
    "print(\"CUDA available:\", torch.cuda.is_available()) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "060d2d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9763b321dcc4c5e8401ac838cfcf304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\Data Science\\Personal Projects\\Text to SQL Assistant\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd992f0d9aa447c981231a063586f1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6471f5510cd343058b54ed64a5279330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac62507516b4490ebf7c1fde687fdeac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\Data Science\\Personal Projects\\Text to SQL Assistant\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--cssupport--t5-small-awesome-text-to-sql. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5c5411a791449c8e1daced0ee78bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The generated SQL query is: SELECT student_id FROM students WHERE NOT student_id IN (SELECT student_id FROM student_course_attendance)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319e7758fe5d435b82c8be406169b2ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Initialize the tokenizer from Hugging Face Transformers library\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "# Load the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = T5ForConditionalGeneration.from_pretrained('cssupport/t5-small-awesome-text-to-sql')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def generate_sql(input_prompt):\n",
    "    # Tokenize the input prompt\n",
    "    inputs = tokenizer(input_prompt, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_length=512)\n",
    "    \n",
    "    # Decode the output IDs to a string (SQL query in this case)\n",
    "    generated_sql = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return generated_sql\n",
    "\n",
    "\n",
    "input_prompt = \"tables:\\n\" + \"CREATE TABLE student_course_attendance (student_id VARCHAR); CREATE TABLE students (student_id VARCHAR)\" + \"\\n\" + \"query for:\" + \"List the id of students who never attends courses?\"\n",
    "\n",
    "generated_sql = generate_sql(input_prompt)\n",
    "\n",
    "print(f\"The generated SQL query is: {generated_sql}\")\n",
    "#OUTPUT: The generated SQL query is: SELECT student_id FROM students WHERE NOT student_id IN (SELECT student_id FROM student_course_attendance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926a7878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "#input_prompt = \"tables:\\n\" + \"CREATE TABLE Catalogs (date_of_latest_revision VARCHAR)\" + \"\\n\" +\"query for: Find the dates on which more than one revisions were made.\"\n",
    "#input_prompt = \"tables:\\n\" + \"CREATE TABLE table_22767 ( \\\"Year\\\" real, \\\"World\\\" real, \\\"Asia\\\" text, \\\"Africa\\\" text, \\\"Europe\\\" text, \\\"Latin America/Caribbean\\\" text, \\\"Northern America\\\" text, \\\"Oceania\\\" text )\" + \"\\n\" +\"query for:what will the population of Asia be when Latin America/Caribbean is 783 (7.5%)?.\"\n",
    "#input_prompt = \"tables:\\n\" + \"CREATE TABLE procedures ( subject_id text, hadm_id text, icd9_code text, short_title text, long_title text ) CREATE TABLE diagnoses ( subject_id text, hadm_id text, icd9_code text, short_title text, long_title text ) CREATE TABLE lab ( subject_id text, hadm_id text, itemid text, charttime text, flag text, value_unit text, label text, fluid text ) CREATE TABLE demographic ( subject_id text, hadm_id text, name text, marital_status text, age text, dob text, gender text, language text, religion text, admission_type text, days_stay text, insurance text, ethnicity text, expire_flag text, admission_location text, discharge_location text, diagnosis text, dod text, dob_year text, dod_year text, admittime text, dischtime text, admityear text ) CREATE TABLE prescriptions ( subject_id text, hadm_id text, icustay_id text, drug_type text, drug text, formulary_drug_cd text, route text, drug_dose text )\" + \"\\n\" +\"query for:\" + \"what is the total number of patients who were diagnosed with icd9 code 2254?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac1469c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT AVG(midd_house_value) FROM housing WHERE median_income > 5\n"
     ]
    }
   ],
   "source": [
    "input_prompt = \"\"\"\n",
    "tables:\n",
    "CREATE TABLE housing (\n",
    "    longitude REAL,\n",
    "    latitude REAL,\n",
    "    housing_median_age REAL,\n",
    "    total_rooms REAL,\n",
    "    total_bedrooms REAL,\n",
    "    population REAL,\n",
    "    households REAL,\n",
    "    median_income REAL,\n",
    "    median_house_value REAL\n",
    ")\n",
    "query for: What is the average median_house_value for houses with median_income > 5?\n",
    "\"\"\"\n",
    "\n",
    "generated_sql = generate_sql(input_prompt)\n",
    "print(generated_sql)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bca10d",
   "metadata": {},
   "source": [
    "### Extract schema directly from SQLite database and feed it into the model prompt automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7218ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3, pandas as pd, difflib, re, textwrap\n",
    "\n",
    "db_path = '../data/housing.db'\n",
    "# 1) read schema from DB\n",
    "def get_schema_and_columns(db_path: str, table_name: str):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(f\"PRAGMA table_info({table_name});\")\n",
    "    info = cur.fetchall()\n",
    "    conn.close()\n",
    "    if not info:\n",
    "        raise ValueError(f\"Table '{table_name}' not found in {db_path}\")\n",
    "    ddl = \"CREATE TABLE {t} (\\n{cols}\\n)\".format(\n",
    "        t=table_name,\n",
    "        cols=\",\\n\".join([f\"    {row[1]} {row[2]}\" for row in info])\n",
    "    )\n",
    "    columns = [row[1] for row in info]\n",
    "    return ddl, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38e37823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) normalize user synonyms before prompting \n",
    "ALIASES = {\n",
    "    # map synonyms (left) to real column names (right) in your DB\n",
    "    \"median_income\": \"MedInc\",\n",
    "    \"median house value\": \"MedHouseVal\",\n",
    "    \"house age\": \"HouseAge\",\n",
    "    \"avg rooms\": \"AveRooms\",\n",
    "    \"average rooms\": \"AveRooms\",\n",
    "    \"avg bedrooms\": \"AveBedrms\",\n",
    "    \"average bedrooms\": \"AveBedrms\",\n",
    "    \"lat\": \"Latitude\",\n",
    "    \"lng\": \"Longitude\",\n",
    "}\n",
    "\n",
    "def normalize_question(question: str) -> str:\n",
    "    for alias, column in ALIASES.items():\n",
    "        question = question.replace(alias, column)\n",
    "    return question\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8dd772dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3) prompt builder that constrains the model ---\n",
    "def build_prompt(db_path: str, table: str, question: str) -> str:\n",
    "    ddl, cols = get_schema_and_columns(db_path, table)\n",
    "    col_list = \", \".join(cols)\n",
    "    question = normalize_question(question)\n",
    "    rules = textwrap.dedent(f\"\"\"\n",
    "    Rules:\n",
    "    - Use ONLY these columns: {col_list}\n",
    "    - The table name is exactly `{table}` (no aliases).\n",
    "    - Return a SINGLE SQL statement, no commentary.\n",
    "    - Use reasonable numeric ranges (Latitude in [-90, 90], Longitude in [-180, 180]).\n",
    "    \"\"\").strip()\n",
    "    return f\"tables:\\n{ddl}\\n{rules}\\nquery for: {question}\", cols\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93333b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example: housing.db schema\n",
    "# db_path = '../data/housing.db'\n",
    "# table_name = 'housing'\n",
    "# schema = get_schema(db_path, table_name)\n",
    "# # \n",
    "# print(schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7462e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 4) validate + auto-repair if a column doesnâ€™t exist ---\n",
    "def try_explain_sql(conn, sql: str):\n",
    "    # We use EXPLAIN to validate structure without running the full query\n",
    "    return pd.read_sql_query(\"EXPLAIN \" + sql, conn)\n",
    "\n",
    "def validate_and_fix_sql(sql: str, db_path: str, table: str, cols: list):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    try:\n",
    "        try_explain_sql(conn, sql)\n",
    "        return sql, None  # valid\n",
    "    except Exception as e:\n",
    "        msg = str(e)\n",
    "        m = re.search(r\"no such column: (\\w+)\", msg, re.I)\n",
    "        if m:\n",
    "            bad = m.group(1)\n",
    "            match = difflib.get_close_matches(bad, cols, n=1, cutoff=0.6)\n",
    "            if match:\n",
    "                fixed = re.sub(rf\"\\b{bad}\\b\", match[0], sql)\n",
    "                try:\n",
    "                    try_explain_sql(conn, fixed)\n",
    "                    return fixed, f\"ðŸ©¹ Replaced `{bad}` â†’ `{match[0]}`\"\n",
    "                except Exception:\n",
    "                    pass\n",
    "        return None, f\"Validation failed: {msg}\"\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b625ed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5) end-to-end guarded generation ---\n",
    "def generate_sql_guarded(question: str, db_path=\"../data/housing.db\", table=\"housing\", max_attempts=2):\n",
    "    prompt, cols = build_prompt(db_path, table, question)\n",
    "    sql = generate_sql(prompt)  # uses your working HF model function\n",
    "\n",
    "    for _ in range(max_attempts):\n",
    "        fixed_sql, note = validate_and_fix_sql(sql, db_path, table, cols)\n",
    "        if fixed_sql:\n",
    "            if note:\n",
    "                print(note)\n",
    "            return fixed_sql\n",
    "        # If invalid, re-prompt the model with the error and allowed columns\n",
    "        error_msg = note or \"Invalid SQL.\"\n",
    "        reprompt = (\n",
    "            f\"{prompt}\\n\\nPrevious SQL:\\n{sql}\\n\\n\"\n",
    "            f\"Error: {error_msg}\\n\"\n",
    "            f\"Regenerate a valid SQL using ONLY these columns: {', '.join(cols)}.\\n\"\n",
    "            f\"Return just the SQL.\"\n",
    "        )\n",
    "        sql = generate_sql(reprompt)\n",
    "\n",
    "    return sql  # best effort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "45ac9000",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'difflib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Data Science\\Personal Projects\\Text to SQL Assistant\\.venv\\Lib\\site-packages\\pandas\\io\\sql.py:2664\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2663\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2664\u001b[39m     \u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2665\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[31mOperationalError\u001b[39m: no such column: HypertAge",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mDatabaseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mvalidate_and_fix_sql\u001b[39m\u001b[34m(sql, db_path, table, cols)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[43mtry_explain_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msql\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m sql, \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# valid\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mtry_explain_sql\u001b[39m\u001b[34m(conn, sql)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtry_explain_sql\u001b[39m(conn, sql: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# We use EXPLAIN to validate structure without running the full query\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEXPLAIN \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Data Science\\Personal Projects\\Text to SQL Assistant\\.venv\\Lib\\site-packages\\pandas\\io\\sql.py:528\u001b[39m, in \u001b[36mread_sql_query\u001b[39m\u001b[34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m--> \u001b[39m\u001b[32m528\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Data Science\\Personal Projects\\Text to SQL Assistant\\.venv\\Lib\\site-packages\\pandas\\io\\sql.py:2728\u001b[39m, in \u001b[36mSQLiteDatabase.read_query\u001b[39m\u001b[34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m   2717\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_query\u001b[39m(\n\u001b[32m   2718\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2719\u001b[39m     sql,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2726\u001b[39m     dtype_backend: DtypeBackend | Literal[\u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2727\u001b[39m ) -> DataFrame | Iterator[DataFrame]:\n\u001b[32m-> \u001b[39m\u001b[32m2728\u001b[39m     cursor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2729\u001b[39m     columns = [col_desc[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor.description]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Data Science\\Personal Projects\\Text to SQL Assistant\\.venv\\Lib\\site-packages\\pandas\\io\\sql.py:2676\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2675\u001b[39m ex = DatabaseError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecution failed on sql \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2676\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mDatabaseError\u001b[39m: Execution failed on sql 'EXPLAIN SELECT AVG(HypertAge) FROM housing WHERE MedInc > 5 AND Latitude > 35': no such column: HypertAge",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m question = \u001b[33m\"\u001b[39m\u001b[33mAverage house age for blocks with MedInc > 5 and Latitude > 35\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m safe_sql = \u001b[43mgenerate_sql_guarded\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Final SQL:\u001b[39m\u001b[33m\"\u001b[39m, safe_sql)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mgenerate_sql_guarded\u001b[39m\u001b[34m(question, db_path, table, max_attempts)\u001b[39m\n\u001b[32m      4\u001b[39m sql = generate_sql(prompt)  \u001b[38;5;66;03m# uses your working HF model function\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_attempts):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     fixed_sql, note = \u001b[43mvalidate_and_fix_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m fixed_sql:\n\u001b[32m      9\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m note:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mvalidate_and_fix_sql\u001b[39m\u001b[34m(sql, db_path, table, cols)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m m:\n\u001b[32m     16\u001b[39m     bad = m.group(\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     match = \u001b[43mdifflib\u001b[49m.get_close_matches(bad, cols, n=\u001b[32m1\u001b[39m, cutoff=\u001b[32m0.6\u001b[39m)\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m match:\n\u001b[32m     19\u001b[39m         fixed = re.sub(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mb\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbad\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\\\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m, match[\u001b[32m0\u001b[39m], sql)\n",
      "\u001b[31mNameError\u001b[39m: name 'difflib' is not defined"
     ]
    }
   ],
   "source": [
    "question = \"Average house age for blocks with MedInc > 5 and Latitude > 35\"\n",
    "safe_sql = generate_sql_guarded(question)\n",
    "print(\"âœ… Final SQL:\", safe_sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a506eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: add the schema to the prompt and generate SQL query\n",
    "def build_prompt(schema, question):\n",
    "    prompt = f\"tables:\\n{schema}\\nquery for: {question}\"\n",
    "    return prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb150d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT AVG(HorseAge) FROM housing WHERE Latitude > 5\n"
     ]
    }
   ],
   "source": [
    "# usage\n",
    "question = \"What is the average median_house_value for houses with median_income > 5?\"\n",
    "input_prompt = build_prompt(schema, question)\n",
    "generated_sql = generate_sql(input_prompt)\n",
    "print(generated_sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ba7e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68e4b3f8",
   "metadata": {},
   "source": [
    "### Execute the suggested SQL query from the housing.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6900fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "no such column: HorseAge",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m     conn.close()\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m results = \u001b[43mrun_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerated_sql\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mrun_query\u001b[39m\u001b[34m(db_path, query)\u001b[39m\n\u001b[32m      3\u001b[39m conn = sqlite3.connect(db_path)\n\u001b[32m      4\u001b[39m cursor = conn.cursor()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m results = cursor.fetchall()\n\u001b[32m      7\u001b[39m conn.close()\n",
      "\u001b[31mOperationalError\u001b[39m: no such column: HorseAge"
     ]
    }
   ],
   "source": [
    "# execute the generated SQL query against the database\n",
    "def run_query(db_path, query):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(query)\n",
    "    results = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return results\n",
    "results = run_query(db_path, generated_sql)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37b9b6a",
   "metadata": {},
   "source": [
    "### Save outputs\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a217a56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Query saved to ..\\data\\generated_queries.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "results_file = Path(\"../data/generated_queries.csv\")\n",
    "\n",
    "# Example: log prompt + SQL\n",
    "log = pd.DataFrame([{\n",
    "    \"input_prompt\": input_prompt,\n",
    "    \"generated_sql\": generated_sql\n",
    "}])\n",
    "\n",
    "if results_file.exists():\n",
    "    log.to_csv(results_file, mode=\"a\", header=False, index=False)\n",
    "else:\n",
    "    log.to_csv(results_file, index=False)\n",
    "\n",
    "print(\"âœ… Query saved to\", results_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
